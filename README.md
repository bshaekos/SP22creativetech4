# Creative Tech 4 - Spring 2022

## Project 1: Rube Goldberg Machine 

### Tools:

HTML, CSS and IFTT

### Timeline: 

3 weeks

### Teammate: 

Yining Gao

### Advisors:

Maxim Safioulline and Ben Hooker

### Project Brief: 

The Web was built around the concept of requests and responses - a constant back and forth between a server on the Internet and a browser on your computer. As it grew and expanded the need arose to get exchange going not just between a person and a machine but among many machines.

A user initiates a single action - a click of a button, a text entry, a page scroll - and the browser triggers a chain of events, most of them hidden behind the veil of the Cloud, to pass around some data from one server to another, like a ball in a pinball machine. The data can be used to request other data, to trigger different responses from servers, to capture more data. It can be formatted, rearranged, displayed in different contexts, - juxtaposed with other data.

In the spirit of Rube Goldberg's fascination with the mechanism over the end result - how can we build similar systems in the digital realm? What kind of data could be passed around? With services could be chained together to produce some unexpected outcomes? What would the triggers look like - and the end results? None of those need to be practical, efficient or even reasonable - the focus is on the celebration of the chains of events and the mechanisms that enable them.

### Process Sketches:

First, from a list of APIs provided by our professors, Yining and I outlined the APIs that we found most interesting. Second, we discussed and rouhgly sketeched how we might connect those APIs togethered based off of the available data. Third, we began formatting the code so that we could retrieve the exact piece of information from each API. Lastly, we had to modify our initial ideas so that the entire string of APIs could function properly.


![Yining   Blake - RUBE GOLDBERG MACHINE - Process Sketches](https://user-images.githubusercontent.com/76088958/164383824-9c80c666-1a1c-4811-b1f0-4d02b2d840f4.jpg)


### System Architecture:

In the end the mix of APIs changed in order to successfully complete a Rube Goldberg machine. 

![Yining   Blake - RUBE GOLDBERG MACHINE - System Architecture](https://user-images.githubusercontent.com/76088958/164376567-c9c4c608-d906-451e-901c-77a9c4ec1439.jpg)


### Project Documentation:


https://user-images.githubusercontent.com/76088958/160047614-8f8afd4e-f3a1-475e-9e94-02c47cc75a2b.mp4


[Rube Goldberg Machine_4.pdf](https://github.com/bshaekos/SP22creativetech4/files/8347009/Rube.Goldberg.Machine_4.pdf)


https://user-images.githubusercontent.com/76088958/160048030-297c0509-1142-430f-adb6-fcd4e668d8b4.mp4


[Rube Goldberg Machine_3.pdf](https://github.com/bshaekos/SP22creativetech4/files/8347008/Rube.Goldberg.Machine_3.pdf)


### Reflection:

Overall, I found the project a lot of fun and a great opportunity for me to further my front-end coding skills. I had not worked with APIs before so it gave me insight into how the internet generally functions. In addition, I become more knowledgeable about the meaning of HTML status codes as Yining and I wrote GET requests to certain services. I was most frustrated by the limitations of HTML in modifying the data once we received it back from the service. If I had more time, I would have liked to add some JavaScript to manipulate the data more so that we didn't have to change our initial vision of the project. Also, the interpretation of some of the API documentation was quite ambiguous, which led to moments of uncertainty as to how to get to the data. 


## Project 2 - Multiplayer Manufacturing Online Sitting Arena (MiMOSA)

### Tools:

Axis Neuron, Blender, Gravity Sketch, Metashape Pro, Mixamo, Tilt Brush and Unity 

### Timeline: 

3 weeks

### Advisors:

Jenny Rodenhouse, Maxim Safioulline and Ben Hooker

### Project Brief: 

After World War I, many artists, writers, and creative intellectuals started to question every aspect of their culture that had allowed the horrors of war to occur. Artists started to think about how technology, consumerism, art, and politics were all interrelated. Romanian-French poet Tristan Tzara noted, "The beginnings of Dada were not the beginnings of art, but of disgust." Artists and writers such as Tzara, Hugo Ball, Man Ray, Hannah HÃ¶ch and Max Ernst decided that the only way to respond to these realizations was through irreverent and (potentially) nonsensical works. Dada artists used techniques such as collage, assemblage, and photomontage to form their works, creating new linguistic and visual languages that attempted to exist outside the rigid structures of contemporary society. The term Dada itself, though contested in origin, is said to come from its meaning of both 'Yes, yes' in Romanian and 'rocking horse' in French, demonstrating its transnational origins. By incorporating found materials into their work, creatives began to break down the distinctions between art and real life by demonstrating that art is always produced from real life. 

Today, we are feeling similar extremes of horror, disgust, and utter confusion. How might our contemporary observations of technology, consumerism, art, and politics manifest into a formal reaction and creative proposition

Explore making mixed-reality chairs by using the technique and concept of assembling, a three-dimensional alternative to collage, a technique of composing work by combining various found models (real and physical), and online materials not normally associated with one another. Through this process, we will explore new forms of manufacturing and human factors in design

### Project Documentation:

I used the Agisoft software to stitch together a 100+ photos that I captured of a chair found in the MDP studio. Then, I imported the .obj file into Blender and worked the model (e.g., removed extraneous information/aspects, smoothed the model to appear more like metal). 

Here are some examples of the photos that I captured of the physical chair:

![IMG_0151](https://user-images.githubusercontent.com/76088958/164580768-943a06f0-b835-4c67-a671-d6b9eacd1a88.JPG)

![IMG_0156](https://user-images.githubusercontent.com/76088958/164580784-97ddab77-b76e-4ced-bd41-bd41e606a0a2.JPG)

![IMG_0161](https://user-images.githubusercontent.com/76088958/164580795-16afeb6a-bb87-4c69-8dfc-660b254fae90.JPG)

![IMG_0166](https://user-images.githubusercontent.com/76088958/164580844-9e02262e-3935-423b-8587-29f0e35fe725.JPG)

![IMG_0173](https://user-images.githubusercontent.com/76088958/164580945-1bd3683a-5fd4-4a77-88ab-7dfeb40a2f6f.JPG)

![IMG_0184](https://user-images.githubusercontent.com/76088958/164580965-ea44e38d-8cd3-48ee-9abb-68cb6a45d803.JPG)

![IMG_0250](https://user-images.githubusercontent.com/76088958/164581046-3731c61f-0100-44a8-9b1e-8396c03e49cd.JPG)

![IMG_0259](https://user-images.githubusercontent.com/76088958/164581072-7eac4cc7-cce1-42ab-8061-65dfee98f37a.JPG)

Here is the point cloud generated in Metashape, showing all of the images and angles that generated the initial 3D model:

![Metashape-Point Cloud](https://user-images.githubusercontent.com/76088958/164619971-4e00424d-4425-42ee-ab9a-0affb1b0f9a9.png)

Here is the final output from Blender:

![Photogram-Chair](https://user-images.githubusercontent.com/76088958/164579286-37ff1923-75c5-4846-a997-0497a3f12811.png)

In addition, I motion captured my body and rigged the motion capture to a Maximo character. I placed both the chair and the rigged character into Unity scene to capture this video:

![Walking-Sitting_Animation](https://user-images.githubusercontent.com/76088958/164609462-0df42665-8670-49f1-ac4d-58c8e430150a.gif)

In addition to using photogrammetry, I used Blender to create mash-ups of free 3D models available online. 

Here are the three chairs and related scenes: 

![Lady_Clocks_Game-Chair](https://user-images.githubusercontent.com/76088958/164609935-23fa58f4-cdd5-4430-90c6-a47a5bdd742f.png)

![Mushroom_at_the_edge_of_the_World-Chair](https://user-images.githubusercontent.com/76088958/164609955-a8e54ee3-2260-4389-ba01-c0d0296962bc.png)

![From_Death_Due_Us_Part-Chair](https://user-images.githubusercontent.com/76088958/164609972-e0d2486a-268e-4dd2-bf29-5bc2ef65da8d.png)

Finally, I used Tilt Brush to create a chair in VR and imported it into Blender, see below. 

![VR-Chair_Scene](https://user-images.githubusercontent.com/76088958/164618010-8f66e5e7-52b2-48aa-8c78-aa2f5b8293b1.png)

### Reflection:

I was super excited to start working in Blender and during the project I realized that I have an affinity for the tool. I really enjoyed the workflow of Blender to Unity with a motion capture animation. I decided on this route instead of the workflow of tying the digital model to a physical chair as the final lesson plan outlined. The reason for this change was due to the technological challenges in connecting the VR headset for live editing in Unity, and the fact that the inside-out tracking on the headset made it difficult for accuracy. I liked the workflow from VR to Blender as well but I could not figure out how to add the images from Tilt Brush into the Blender model. Regardless, I believe that VR allows me to create a basic form that I can refine in Blender for a final output. I definitely plan on continuing my exposure to 3D modeling and animation. 


## Project 4 - Personal Project

### Tools:

Unity (VFX Graph) and Axis Neuron

### Timeline: 

2 weeks

### Advisors:

Maxim Safioulline, Jenny Rodenhouse and Ben Hooker

### Project Brief: 


### Process:

![Unity_Animation](https://user-images.githubusercontent.com/76088958/164618827-67753331-1d7c-41d7-8272-e7df17a22ea2.png)

![Unity_Scene](https://user-images.githubusercontent.com/76088958/164618840-b0655ed2-01e7-45de-9410-4da664383634.png)

![VFX_Particle_1](https://user-images.githubusercontent.com/76088958/164618854-9d192181-96c2-43be-8587-ac015b7c9e00.png)

![VFX_Particle_2](https://user-images.githubusercontent.com/76088958/164618875-b44e9863-1134-4e22-9ff2-62d5e83ac635.png)

### Project Documentation:




